{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change dir in jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dvc-cc-hide\n",
    "if os.getcwd().endswith('source'):\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Argparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print('Tensorflow runs on the GPU: ', tf.config.list_physical_devices('GPU'))\n",
    "print()\n",
    "parser = argparse.ArgumentParser();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training\n",
    "parser.add_argument('-lr', '--learning-rate', type=float, help='', default=0.0001)\n",
    "parser.add_argument('-b','--batch-size', type=int, help='', default=64)\n",
    "parser.add_argument('--num-of-epochs', type=int, help='', default=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model structure\n",
    "parser.add_argument('--activation-function', type=str, help='', default='relu')\n",
    "parser.add_argument('--kernel-width', type=int, help='', default=3)\n",
    "parser.add_argument('--average-kernels', type=int, help='', default=32)\n",
    "parser.add_argument('--num-of-conv-layers', type=int, help='', default=5)\n",
    "parser.add_argument('--kernel-increasing-factor', type=float, help='', default=1.2)\n",
    "parser.add_argument('--maxpool-after-n-layer', type=int, help='', default=0)\n",
    "parser.add_argument('--dropout-factor-after-conv', type=float, help='', default=0.1)\n",
    "parser.add_argument('--dropout-factor-after-maxp', type=float, help='', default=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dvc-cc-show\n",
    "args = parser.parse_args()\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dvc-cc-hide\n",
    "args = parser.parse_args(\"--num-of-epochs 5 -b 16\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "padding = 'same'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel2d = (args.kernel_width, args.kernel_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "for i in range(args.num_of_conv_layers):\n",
    "    kernels = args.average_kernels * (args.kernel_increasing_factor ** (i-(args.num_of_conv_layers/2.)))\n",
    "    kernels = int(kernels+0.5)\n",
    "    \n",
    "    if i == 0:\n",
    "        input_shape = list([96,96,3])\n",
    "        # use_cropping:\n",
    "        input_shape[0] -= 10\n",
    "        input_shape[1] -= 10 \n",
    "        \n",
    "        model.add(Conv2D(kernels, kernel2d, padding=padding,\n",
    "                 input_shape=input_shape))\n",
    "    else:\n",
    "        model.add(Conv2D(kernels, kernel2d, padding=padding))\n",
    "    model.add(Activation(args.activation_function))\n",
    "    if args.maxpool_after_n_layer > 0 and (i+1) % args.maxpool_after_n_layer == 0:\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        if args.dropout_factor_after_maxp > 0:\n",
    "            model.add(Dropout(args.dropout_factor_after_maxp))\n",
    "    elif args.dropout_factor_after_conv > 0:\n",
    "        model.add(Dropout(args.dropout_factor_after_conv))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "if args.dropout_factor_after_maxp > 0:\n",
    "    model.add(Dropout(args.dropout_factor_after_maxp))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(args.learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy',tf.keras.metrics.AUC()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_data_pcam(x_path,y_path,bz=args.batch_size):\n",
    "    x = h5py.File(x_path,'r', libver='latest',swmr=True)['x']\n",
    "    y = h5py.File(y_path,'r', libver='latest', swmr=True)['y']\n",
    "\n",
    "    datalen = len(x)\n",
    "    while True:\n",
    "        indizies = None\n",
    "        while indizies is None or len(indizies) == bz:\n",
    "            indizies = list(np.unique(sorted(np.random.randint(datalen,size=bz))))\n",
    "        \n",
    "        x_data = np.array(x[indizies])\n",
    "        \n",
    "        # normalize_input\n",
    "        x_data = x_data/256.0\n",
    "        \n",
    "        #use_cropping\n",
    "        r = np.random.randint(10)\n",
    "        r2 = np.random.randint(10)\n",
    "        x_data = x_data[:,r:-10+r,r2:-10+r2]\n",
    "        \n",
    "        # flip_input\n",
    "        if np.random.randint(2) == 1:\n",
    "            x_data = x_data[:,::-1]\n",
    "        if np.random.randint(2) == 1:\n",
    "            x_data = x_data[:,:,::-1]\n",
    "        \n",
    "        yield x_data, np.array([[1,0],[0,1]])[y[indizies][:,0,0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard('tensorboard')\n",
    "history = model.fit_generator(next_data_pcam(\n",
    "                             'data/camelyonpatch_level_2_split_train_x.h5',\n",
    "                             'data2/camelyonpatch_level_2_split_train_y.h5'),\n",
    "                        validation_steps=10,\n",
    "                        steps_per_epoch=30,\n",
    "                        epochs=args.num_of_epochs,\n",
    "                        validation_data=next_data_pcam(\n",
    "                             'data3/camelyonpatch_level_2_split_valid_x.h5',\n",
    "                             'data4/camelyonpatch_level_2_split_valid_y.h5'),\n",
    "                        workers=1,\n",
    "                        verbose=2,\n",
    "                        use_multiprocessing=False,\n",
    "                        callbacks=[tensorboard])\n",
    "\n",
    "model.save_weights('tf_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('outputs'):\n",
    "    os.mkdir('outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outputs/all-history.json','w') as f:\n",
    "    json.dump(str(history.history),f)\n",
    "\n",
    "params = {}\n",
    "for p in history.history:\n",
    "    if p.find('loss') >= 0:\n",
    "        params[p] = np.min(history.history[p])\n",
    "    else:\n",
    "        params[p] = np.max(history.history[p])\n",
    "        \n",
    "with open('outputs/history-summary.json','w') as f:\n",
    "    json.dump(str(params),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM STOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "plt.plot(range(len(loss)), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
